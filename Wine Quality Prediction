# Step 1: Import Libraries
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.ensemble import RandomForestClassifier
from sklearn.linear_model import SGDClassifier
from sklearn.svm import SVC
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report

# Step 2: Load Dataset
# Replace the path with your actual dataset path
# Example dataset: 'winequality-red.csv' or 'winequality-white.csv' from UCI repo
data = pd.read_csv("winequality-red.csv") # Red wine dataset (use "winequality-white.csv" for white wine)

# Step 3: Data Preprocessing
# Check for missing values
print("Missing values:", data.isnull().sum())

# Explore the dataset
print("Dataset info:\n", data.info())
print("Dataset preview:\n", data.head())

# Step 4: Feature and Target Variables
# Features: All columns except 'quality' (the target)
X = data.drop('quality', axis=1)

# Target: 'quality' column
y = data['quality']

# Step 5: Train-Test Split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Step 6: Data Standardization
# Standardizing the data (mean = 0, std = 1) for SGD and SVC models
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# Step 7: Model Training and Evaluation

# 1. Random Forest Classifier
rf_model = RandomForestClassifier(n_estimators=100, random_state=42)
rf_model.fit(X_train, y_train)
rf_pred = rf_model.predict(X_test)

# 2. Stochastic Gradient Descent Classifier
sgd_model = SGDClassifier(random_state=42)
sgd_model.fit(X_train_scaled, y_train)
sgd_pred = sgd_model.predict(X_test_scaled)

# 3. Support Vector Classifier
svc_model = SVC(random_state=42)
svc_model.fit(X_train_scaled, y_train)
svc_pred = svc_model.predict(X_test_scaled)

# Step 8: Evaluate Models

# Random Forest Evaluation
print("\nRandom Forest Classifier Evaluation:")
print("Accuracy:", accuracy_score(y_test, rf_pred))
print(classification_report(y_test, rf_pred))
print("Confusion Matrix:\n", confusion_matrix(y_test, rf_pred))

# SGD Classifier Evaluation
print("\nStochastic Gradient Descent Evaluation:")
print("Accuracy:", accuracy_score(y_test, sgd_pred))
print(classification_report(y_test, sgd_pred))
print("Confusion Matrix:\n", confusion_matrix(y_test, sgd_pred))

# SVC Classifier Evaluation
print("\nSupport Vector Classifier Evaluation:")
print("Accuracy:", accuracy_score(y_test, svc_pred))
print(classification_report(y_test, svc_pred))
print("Confusion Matrix:\n", confusion_matrix(y_test, svc_pred))

# Step 9: Visualization

# Feature Importance - Random Forest
feature_importance = rf_model.feature_importances_
plt.figure(figsize=(10, 6))
sns.barplot(x=X.columns, y=feature_importance)
plt.title('Feature Importance - Random Forest')
plt.xticks(rotation=90)
plt.show()

# Distribution of wine quality
plt.figure(figsize=(8, 6))
sns.countplot(data=data, x='quality', palette='viridis')
plt.title('Distribution of Wine Quality')
plt.show()

# Correlation heatmap
plt.figure(figsize=(10, 8))
sns.heatmap(data.corr(), annot=True, cmap='coolwarm', fmt='.2f')
plt.title('Correlation Heatmap')
plt.show()
