# Step 1: Import libraries
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.cluster import KMeans
from sklearn.preprocessing import StandardScaler
from datetime import datetime

# Step 2: Load the dataset
# Replace 'customer_data.csv' with your dataset path
data = pd.read_csv("customer_data.csv")

# Step 3: Explore the dataset
print("First few rows of the dataset:")
print(data.head())
print("\nDataset Info:")
print(data.info())
print("\nSummary Statistics:")
print(data.describe())

# Step 4: Handle missing or inconsistent data
# Check for missing values
print("\nMissing values in each column:")
print(data.isnull().sum())

# Drop rows with missing values (or handle them appropriately)
data.dropna(inplace=True)

# Clean up column names
data.columns = data.columns.str.strip().str.lower().str.replace(' ', '_')

# Step 5: Feature Engineering
# Create Recency, Frequency, and Monetary (RFM) metrics
# Example for recency: Assume 'last_purchase_date' is in your dataset
data['last_purchase_date'] = pd.to_datetime(data['last_purchase_date'])
data['recency'] = (datetime.now() - data['last_purchase_date']).dt.days

# Aggregate for Frequency and Monetary
rfm = data.groupby('customerid').agg({
    'recency': 'min', # Minimum days since last purchase
    'purchase_amount': 'sum', # Total monetary value
    'purchase_id': 'count' # Frequency of purchases
}).reset_index()

# Rename for clarity
rfm.rename(columns={'purchase_id': 'frequency', 'purchase_amount': 'monetary'}, inplace=True)

# Step 6: Data Normalization
scaler = StandardScaler()
rfm_scaled = scaler.fit_transform(rfm[['recency', 'frequency', 'monetary']])

# Step 7: Apply Clustering Algorithm (K-Means)
# Determine optimal number of clusters using the Elbow Method
sse = []
k_range = range(1, 11)
for k in k_range:
    kmeans = KMeans(n_clusters=k, random_state=42)
    kmeans.fit(rfm_scaled)
    sse.append(kmeans.inertia_)

# Plot the Elbow Curve
plt.figure(figsize=(8, 5))
plt.plot(k_range, sse, marker='o')
plt.title('Elbow Method to Determine Optimal Clusters')
plt.xlabel('Number of Clusters (k)')
plt.ylabel('Sum of Squared Errors (SSE)')
plt.show()

# Choose optimal k (e.g., 4 based on the elbow curve) and fit the model
optimal_k = 4
kmeans = KMeans(n_clusters=optimal_k, random_state=42)
rfm['Cluster'] = kmeans.fit_predict(rfm_scaled)

# Step 8: Visualize Clusters
# Pairplot visualization for clusters
sns.pairplot(rfm, hue='Cluster', palette='tab10', diag_kind='kde')
plt.show()

# Bar plot for average values of RFM metrics in each cluster
cluster_summary = rfm.groupby('Cluster').mean()
cluster_summary.plot(kind='bar', figsize=(10, 6), title="Average RFM Metrics per Cluster")
plt.show()

# Step 9: Insights and Recommendations
print("\nCluster Summary:")
print(cluster_summary)

# Example insights:
# High Recency, Low Monetary: Customers needing re-engagement.
# High Frequency, High Monetary: Loyal, high-valueÂ customers.
